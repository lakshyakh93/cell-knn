#summary Schedule of the project.

= Schedule =

|| *Date* || *Task* ||
|| 05.11.08 || Development environment ||
|| 10.12.08 || Cell k-NN 1.0 ||
|| 14.01.09 || Cell k-NN 2.0 ||
|| 21.01.08 || Evaluation ||

== Cell k-NN 1.0 ==

In the first version of the Cell k-NN program we are going to implement a runnable program which distributes the work among the SPEs. This includes 
 * A program to preprocess the MNIST data, i.e. extract the "interesting" values from a data set and transform the data as required
 * A generic implementation of the k-NN algorithm.
As far as the k-NN algorithm is concerned, we are planning to implement it "as generic as possible", that means, we do not specifically adapt our implementation to the MNIST data sets. For interexchangeability we provide a generic interface consisting of header files, which we are planning to develop in cooperation with the Cuda k-NN Team, if possible.

The general idea is illustrated in the following image:

[http://cell-knn.googlecode.com/files/Distribution%20Simple.png]

As you can see in the image above, the MNIST image is represented as an array of pixels with brightness values (0-255). This is done in the preprocessing of the image. Then the array is split in _n_ parts (_n_ is the number of SPEs available), for which each SPE calculates the distance of the image to all other references. The PPE then sums up all the _n_ distances returned by the SPEs and keeps track of the _k_ nearest images in a sorted list. After all distances between the reference images and the given image have been calculated, the PPE classifies the given image using the _k_ nearest images.

== Cell k-NN 2.0 ==

For version 2.0 of the k-NN implementation we are considering using the [http://www.bsc.es/plantillaG.php?cat_id=179 Cell Superscalar] framework provided by Barcelona Supercomputer Center.