#summary Overview of the k-Nearest-Neighbour algorithm.

= Basic Idea = 

The k-Nearest-Neighbour (k-NN) algorithm is a simple machine learning algorithm. The idea is to project objects to a vector space of _n_ dimensions. The algorithm compares a _query point_, i.e. an object to classify, to a set of already classified objects, often called the _training set_ (a set of _training points_). The algorithm determines the _k_ nearest neighbours in the vector space by calculating the distance of the query point to all training points according to some distance measure, like in our case the quadratic [http://en.wikipedia.org/wiki/Euclidean_distance euclidean distance]. A query point is classified by a majority vote of its neighbours, with the object being assigned to the label most common amongst its _k_ nearest neighbors. _k_ is a positive integer, typically small.

See below an implementation of the k-NN algorithm in a Java like pseudo code.

{{{
double distance(Point query, Point reference) {
        // We use the quadratic euclidean distance.
	int sum = 0;
	
        // Loop 3.
        for (int i = 0; i < query.vector.lenght; i++) {
            int difference = reference.vector[i] - query.vector[i];
	    sum += difference * difference;
	}
	
	return sum;
}
 
void classify(int k, Point[] querySet, Point[] trainingSet) {
    // Loop 1.
    foreach (query in querySet) {
        // Loop 2.
        foreach (training in trainingSet) {
            // Create a fixed sized sorted map of length k,
            // where we map the distance to a training point.
            SortedMap map = new SortedMap(k);
 
            // Calculate distance of test point to training point.
            double d = distance(query, training);
		
            // Insert training point into sorted list, discarding if training point
            // not within k nearest neighbours to query point.
            map.insert(d, training);
        }
  
        // Do majority vote on k nearest neighbours and
        // assign the corresponding label to the query point.
	query.label = majorityVote(map);
    }
}
}}}

= Parallel implementation variants =

In the code above we have denoted the loops with parallelisation potential with _Loop 1_, _Loop 2_ and _Loop 3_. According to this we can implement 3 different variants of parallel implementations.

== Variant 1 ==
Parallelize _Loop 1_, i.e. the loop over the query points.

== Variant 2 ==
Parallelize _Loop 2_, i.e. the loop over the training points.

== Variant 3 ==
Parallelize _Loop 3_, i.e. the loop over the dimensions of the vector space.